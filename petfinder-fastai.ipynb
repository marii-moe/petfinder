{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import json\n",
    "from functools import partial\n",
    "import pickle as pkl\n",
    "from fastai import *\n",
    "from fastai.collab import *\n",
    "from fastai.tabular import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path('~/.fastai/data/petfinder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniquesInDf(df):\n",
    "    uniqs = {}\n",
    "    for col in df.columns:\n",
    "        uniqs[col] = df[col].sort_values().unique().tolist()\n",
    "    return uniqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the variables in the csv file from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age probably needs some form of help because it clusters around certain numbers\n",
    "NotVars=['Name','Description','AdoptionSpeed',]\n",
    "catVars=['Type','Breed1','Breed2','Gender','Color1', 'Color2', 'Color3',\n",
    "         'MaturitySize','FurLength','Vaccinated', 'Dewormed', 'Sterilized',\n",
    "        'Health','State','RescuerID',]\n",
    "contVars=['Age','Quantity','Fee','VideoAmt','PhotoAmt']\n",
    "cols={'notVars':NotVars,'cat':catVars,'cont':contVars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the metric used by kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QWK(Callback):\n",
    "    def __init__(self, func):\n",
    "        self.func, self.name = func, func.__name__\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.outs=torch.FloatTensor().cpu()\n",
    "        self.targs=torch.FloatTensor().cpu()\n",
    "\n",
    "    def on_batch_end(self, last_output, last_target, train, **kwargs):\n",
    "        maxs=last_output.detach()\n",
    "        self.outs=torch.cat((self.outs.cpu(),maxs.cpu()))\n",
    "        self.targs=torch.cat((self.targs.cpu(),last_target.cpu()))\n",
    "\n",
    "    def on_epoch_end(self, **kwargs):\n",
    "        self.metric = self.func(torch.round(self.outs).long().numpy(),torch.squeeze(self.targs.long(),1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    quadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "        \"\"\"\n",
    "        Returns the confusion matrix between rater's ratings\n",
    "        \"\"\"\n",
    "        assert(len(rater_a) == len(rater_b))\n",
    "        if min_rating is None:\n",
    "            min_rating = min(rater_a + rater_b)\n",
    "        if max_rating is None:\n",
    "            max_rating = max(rater_a + rater_b)\n",
    "        num_ratings = int(max_rating - min_rating + 1)\n",
    "        conf_mat = [[0 for i in range(num_ratings)]\n",
    "                    for j in range(num_ratings)]\n",
    "        for a, b in zip(rater_a, rater_b):\n",
    "            conf_mat[a - min_rating][b - min_rating] += 1\n",
    "        return conf_mat\n",
    "\n",
    "\n",
    "    def histogram(ratings, min_rating=None, max_rating=None):\n",
    "        \"\"\"\n",
    "        Returns the counts of each type of rating that a rater made\n",
    "        \"\"\"\n",
    "        if min_rating is None:\n",
    "            min_rating = min(ratings)\n",
    "        if max_rating is None:\n",
    "            max_rating = max(ratings)\n",
    "        num_ratings = int(max_rating - min_rating + 1)\n",
    "        hist_ratings = [0 for x in range(num_ratings)]\n",
    "        for r in ratings:\n",
    "            hist_ratings[r - min_rating] += 1\n",
    "        return hist_ratings\n",
    "\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return 1.0 - numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fullTrain=path/'train'/'train.csv'\n",
    "fullTest=path/'test'/'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fullTrain=pd.read_csv(fullTrain)\n",
    "fullTest=pd.read_csv(fullTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "types={\n",
    "    'PhotoAmt':np.int64\n",
    "}\n",
    "fullTrain=fullTrain.astype(dtype=types)\n",
    "fullTest=fullTest.astype(dtype=types)\n",
    "print(fullTrain.dtypes)\n",
    "print(fullTest.dtypes)\n",
    "fullData=pd.concat([fullTrain,fullTest])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Standardizing the continuous variables, ie variables that vary over a range -inf->+inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for col in fullData[contVars]:\n",
    "    fullTrain[col]=(fullTrain[col]-fullData[col].mean())/fullData[col].std()\n",
    "    fullTest[col]=(fullTest[col]-fullData[col].mean())/fullData[col].std()\n",
    "    fullData[col]=(fullData[col]-fullData[col].mean())/fullData[col].std()\n",
    "fullData[contVars][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fullTrain.to_csv(path/'train'/'normailizedTrain.csv',index=False)\n",
    "fullTest.to_csv(path/'train'/'normailizedTest.csv',index=False)\n",
    "fullData.to_csv(path/'train'/'normailizedData.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finding the unique values for each categorical variable. This is latter used for creating embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "uniqCols = uniquesInDf(fullData)\n",
    "print(uniqCols.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('unique_cols.json', 'w') as file:\n",
    "     file.write(json.dumps(uniqCols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "keysToIndex={}\n",
    "for key in uniqCols.keys():\n",
    "    keysToIndex[key]={}\n",
    "    for i,uniq in enumerate(uniqCols[key]):\n",
    "        keysToIndex[key][uniq]=i+1 #0 is not found\n",
    "keysToIndex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('keysToIndex.json', 'w') as file:\n",
    "     file.write(json.dumps(keysToIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataCats=fullData[cols['cat']].copy()\n",
    "trainCats=fullTrain[cols['cat']].copy()\n",
    "testCats=fullTest[cols['cat']].copy()\n",
    "for column in cols['cat']:\n",
    "    dataCats[column]=dataCats[column].map(keysToIndex[column])\n",
    "    trainCats[column]=trainCats[column].map(keysToIndex[column])\n",
    "    testCats[column]=testCats[column].map(keysToIndex[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fullData[cols['cat']]=dataCats\n",
    "fullTrain[cols['cat']]=trainCats\n",
    "fullTest[cols['cat']]=testCats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fullData.to_csv(path/'train'/'normCatData.csv',index=False)\n",
    "fullTrain.to_csv(path/'train'/'normCatTrain.csv',index=False)\n",
    "fullTest.to_csv(path/'train'/'normCatTest.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullTrain=path/'train'/'train.csv'\n",
    "fullTest=path/'test'/'test.csv'\n",
    "fullTrain=pd.read_csv(fullTrain)\n",
    "fullTest=pd.read_csv(fullTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqTrain = uniquesInDf(fullTrain)\n",
    "uniqTest = uniquesInDf(fullTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqTrain['RescuerID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fullTest),len(fullTest.join(fullTrain,on='RescuerID',rsuffix='_rain',how='inner')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found here that RescuerId is different in train/test datasets. Must split this out as well when creating validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Loading for Initial Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Trying to find an effective way to pretrain the embeddings for the categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "normalPath=path/'train'/'normCatData.csv'\n",
    "fullData=pd.read_csv(normalPath)\n",
    "valid=fullData.sample(frac=0.2, random_state=45321)\n",
    "train=fullData.drop(valid.index)\n",
    "[len(train),len(valid),len(valid)/len(train),len(fullData)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "uniq_cols = uniquesInDf(fullData)\n",
    "print(uniq_cols.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self,cats,labels):\n",
    "        self.cats=cats\n",
    "        self.labels=labels\n",
    "        if(len(self.cats)!=len(self.labels)):\n",
    "            raise ValueError('Labels not same length as inputs!')\n",
    "    def __len__(self):\n",
    "        return len(self.cats)\n",
    "    def __getitem__(self,idx):\n",
    "        return torch.from_numpy(self.cats[idx]),torch.FloatTensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embedCont=cols['cont'].copy()\n",
    "embedCont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainDs=PetDataset(train[cols['cat']].values,train[embedCont].values)\n",
    "validDs=PetDataset(valid[cols['cat']].values,valid[embedCont].values)\n",
    "trainDs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainDl=DataLoader(trainDs, batch_size=128,shuffle=True, num_workers=4)\n",
    "validDl=DataLoader(validDs, batch_size=128,shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pretraining Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Simple \"deep\" linear model for training embeddings\n",
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self,cols,uniq_cols):\n",
    "        super(SimpleLinearModel, self).__init__()\n",
    "        embeds=[]\n",
    "        embed_sz=0\n",
    "        for cat in cols['cat']:\n",
    "            embed_sz+=max(min(len(uniq_cols[cat]),50),4)\n",
    "            embeds.append(nn.Embedding(len(uniq_cols[cat])+1,max(min(len(uniq_cols[cat]),50),4)))\n",
    "        self.embeds=nn.ModuleList(embeds)\n",
    "        self.bn1=nn.BatchNorm1d(embed_sz)\n",
    "        self.l1=nn.Linear(embed_sz,100)#+len(cols['cont']\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.bn2=nn.BatchNorm1d(self.l1.out_features)\n",
    "        self.dp1=nn.Dropout(p=0.2)\n",
    "        self.l2=nn.Linear(self.l1.out_features,5)\n",
    "    def forward(self,cat):\n",
    "        x=[e(cat[:,i]) for i,e in enumerate(self.embeds)]\n",
    "        x=torch.cat(x,1)\n",
    "        #x=torch.cat([x,cont],1)\n",
    "        x=self.bn1(x)\n",
    "        x=self.l1(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.bn2(x)\n",
    "        x=self.dp1(x)\n",
    "        return self.l2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embedCols=cols.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embedCols['cont']=embedCont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model=SimpleLinearModel(embedCols,uniq_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(), lr=0.01,weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "criterion=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(trainDl.dataset))\n",
    "print(len(validDl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train[embedCont].min()\n",
    "train[embedCont].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "db=DataBunch(trainDl,validDl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn=Learner(data=db,model=model,loss_func=nn.MSELoss(),wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(7):  # loop over the dataset multiple times\n",
    "    print('epoch: '+str(epoch))\n",
    "    running_loss = 0.0\n",
    "    training_loss=0.0\n",
    "    for i, data in enumerate(trainDl):\n",
    "        # get the inputs\n",
    "        cats, labels = data\n",
    "        if(len(labels)<=1):\n",
    "            break\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(cats)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 40 == 39:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 40))\n",
    "            running_loss=0.0\n",
    "    with torch.no_grad():\n",
    "        outputs=torch.Tensor([])\n",
    "        validLabels=torch.FloatTensor([])\n",
    "        for i, data in enumerate(validDl):\n",
    "            cats, labels = data\n",
    "            outputs=torch.cat((outputs,model(cats).squeeze(dim=1)))\n",
    "            validLabels=torch.cat((validLabels,labels.float()))\n",
    "        loss = criterion(outputs, validLabels.float())#torch.unsqueeze(,1))\n",
    "        validLoss = loss.item()\n",
    "        avgDeviation=torch.sum(torch.abs(torch.sub(outputs,validLabels.float())))/len(trainDl.dataset)\n",
    "        numBatches=len(trainDl.dataset)/trainDl.batch_size\n",
    "        print('[%d] training loss: %.3f validation loss: %.3f avgDev: %.3f' %\n",
    "                  (epoch + 1, training_loss/numBatches,validLoss,avgDeviation))\n",
    "            \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "state=model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('embeds.pkl', 'wb') as f:\n",
    "    pkl.dump(learn.model.embeds.state_dict(),f, pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The train and test sets do not overlap in rescuerIDs, so splitting based on this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "normalPath=path/'train'/'normCatTrain.csv'\n",
    "fullTrain=pd.read_csv(normalPath)\n",
    "fullData=pd.read_csv(path/'train'/'normCatData.csv')\n",
    "validIndex=fullTrain.RescuerID.isin(pd.Series(fullTrain.RescuerID.unique()).sample(frac=0.1845, random_state=12345))\n",
    "valid=fullTrain[validIndex]\n",
    "train=fullTrain.drop(valid.index)\n",
    "[len(train),len(valid),len(valid)/len(train),len(fullTrain)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "uniq_cols = uniquesInDf(fullData)\n",
    "print(uniq_cols.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self,conts,cats,labels):\n",
    "        self.conts=conts\n",
    "        self.cats=cats\n",
    "        self.x=(conts,cats)\n",
    "        self.labels=labels\n",
    "        if(len(self.conts)!=len(self.cats)):\n",
    "            raise ValueError('Catigorical and continuous variables should be same length')\n",
    "        if(len(self.conts)!=len(self.labels)):\n",
    "            raise ValueError('Labels not same length as inputs!')\n",
    "    def __len__(self):\n",
    "        return len(self.conts)\n",
    "    def __getitem__(self,idx):\n",
    "        return [torch.Tensor(self.conts[idx]),torch.from_numpy(self.cats[idx])],torch.FloatTensor([self.labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.Tensor(train['AdoptionSpeed'].values/4).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainDs=PetDataset(train[cols['cont']].values,train[cols['cat']].values,train['AdoptionSpeed'].values)\n",
    "validDs=PetDataset(valid[cols['cont']].values,valid[cols['cat']].values,valid['AdoptionSpeed'].values)\n",
    "trainDs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainDl=DataLoader(trainDs, batch_size=12535,shuffle=True, num_workers=4)\n",
    "validDl=DataLoader(validDs, batch_size=128,shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "db=DataBunch(trainDl,validDl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainDs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn=Learner(data=db,model=model,loss_func=nn.MSELoss(),metrics=QWK(quadratic_weighted_kappa),wd=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.layer_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "layer_groups = [model.embeds,\n",
    "    nn.ModuleList([model.bn1,model.dp1,model.layers])]\n",
    "learn.layer_groups=layer_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.layer_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainDs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels=[]\n",
    "for input,label in trainDs:\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "counts={}\n",
    "for i in range(0,7):\n",
    "    counts[i]=labels.count(torch.Tensor([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.get_preds(learn.data.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4,1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(16,slice(0.1/1000.0,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainDs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.get_preds(DatasetType.Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_cols.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self,cols,uniq_cols):\n",
    "        super(SimpleLinearModel, self).__init__()\n",
    "        embeds=[]\n",
    "        embed_sz=0\n",
    "        for cat in cols['cat']:\n",
    "            embed_sz+=max(min(len(uniq_cols[cat]),50),4)\n",
    "            embeds.append(nn.Embedding(len(uniq_cols[cat])+1,max(min(len(uniq_cols[cat]),50),4)))\n",
    "        self.embeds=nn.ModuleList(embeds)\n",
    "        self.bn1=nn.BatchNorm1d(embed_sz+len(cols['cont']))\n",
    "        self.dp1=nn.Dropout(p=0.1)\n",
    "        self.embeds=nn.ModuleList(embeds)\n",
    "        self.layers=nn.ModuleList([\n",
    "            nn.Linear(embed_sz+len(cols['cont']),100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(embed_sz+len(cols['cont'])+100,50),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(embed_sz+len(cols['cont'])+100+50,1)\n",
    "        ])\n",
    "    def forward(self,cont,cat):\n",
    "        #cont=x[0]\n",
    "        #cat=x[1]\n",
    "        x=[e(cat[:,i]) for i,e in enumerate(self.embeds)]\n",
    "        x=torch.cat(x,1)\n",
    "        x=torch.cat([x,cont],1)\n",
    "        x=self.bn1(x)\n",
    "        x=self.dp1(x)\n",
    "        lin_in=torch.FloatTensor().cuda()#x.clone()\n",
    "        #first_lin=True\n",
    "        for l in self.layers:\n",
    "            if(isinstance(l,nn.Linear)):\n",
    "                lin_in=torch.cat((lin_in,x),1)\n",
    "                x=l(lin_in)\n",
    "                #lin_cat=range(0,len(lin_out[0])-len(x[0]))\n",
    "                #x=l(x) if(first_lin) else l(torch.cat([x,lin_out[:,lin_cat]],1))\n",
    "                #x=l(x) if(first_lin) else l(torch.cat([x,lin_out],1))\n",
    "                #lin_out=torch.cat([x,lin_out],1)\n",
    "                #first_lin=False\n",
    "            else:\n",
    "                x=l(x)\n",
    "        return torch.squeeze(x,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dmesg for cuda errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dmesg | tail -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SimpleLinearModel(cols,uniq_cols).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds=pkl.load(open('embeds.pkl',mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embeds.load_state_dict(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(model.parameters(), lr=0.01,weight_decay=0.1, betas=(0.9,0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.MSELoss()#partial(quadratic_weighted_kappa, min_rating=None, max_rating=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.embeds.parameters():\n",
    "    p.requires_grad=True\n",
    "next(model.embeds.parameters()).requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 0.373\n",
    "2. 0.433\n",
    "3. 0.444 was without dropout\n",
    "4. 0.349 after removing rescuerId :< 395 place out of 795... have not yet split by rescuerID\n",
    "5. 0.328 after splitting training and validation by the rescuerID... lowering test set to give more training data next\n",
    "6. 0.350 after reclaiming some test data, seems splitting by rescuerID didn't really effect results so much, interesting. Removing the data still a problem. Should implement based on creating an identifier for rescuerID, then using 50 element linear layer representation as an embedding\n",
    "7. 0.260 with loaded frozen embeddings \n",
    "8. 0.319 after allowing training embeddings, was overfitting to start though\n",
    "9. 0.349 Better training with new embeddings!!! Lots of improvements in training regimand that can be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    print('epoch: '+str(epoch))\n",
    "    running_loss = 0.0\n",
    "    training_loss=0.0\n",
    "    for i, data in enumerate(trainDl):\n",
    "        # get the inputs\n",
    "        x, labels = data\n",
    "        if(len(labels)<=1):\n",
    "            break\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(x[0],x[1])\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 40 == 39:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 40))\n",
    "            running_loss=0.0\n",
    "    with torch.no_grad():\n",
    "        outputs=torch.Tensor([])\n",
    "        validLabels=torch.LongTensor([])\n",
    "        for i, data in enumerate(validDl):\n",
    "            x, labels = data\n",
    "            outputs=torch.cat((outputs,model(x[0],x[1]).squeeze(dim=1)))\n",
    "            validLabels=torch.cat((validLabels,labels))\n",
    "        loss = criterion(outputs, validLabels.long())#torch.unsqueeze(,1))\n",
    "        validLoss = loss.item()\n",
    "        outputs=torch.max(outputs,dim=1)[1]#.mul(4).round().int().squeeze(1)\n",
    "        qwk= quadratic_weighted_kappa(outputs,validLabels,min_rating=0,max_rating=4)#.mul(4).round().int(),min_rating=0,max_rating=4)\n",
    "        numBatches=len(trainDl.dataset)/trainDl.batch_size\n",
    "        print('[%d] training loss: %.3f validation loss: %.3f qwk: %.3f' %\n",
    "                  (epoch + 1, training_loss/numBatches,validLoss,qwk))\n",
    "            \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## With Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "--- This is just all incomplete ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Currently have a model that can get 0.444, time to see if images will help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "originalData = pd.read_csv(path/'train'/'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "originalData[['PetID','PhotoAmt']].groupby(by='PhotoAmt').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Most have at least one photo, at most 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
